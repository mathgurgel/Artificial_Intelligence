{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMf4mVRSTOOhq/x1lTiNJTv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Binary Classification Algorithm for Identifying Calisthenics Spots in Images"
      ],
      "metadata": {
        "id": "McAkCgPvUFVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive"
      ],
      "metadata": {
        "id": "Zb9sebyES0PB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJIuihf-3P76",
        "outputId": "f2df9dcc-8088-452e-c5bb-03ba6f14a521"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Requirements"
      ],
      "metadata": {
        "id": "CStqPF-WS5qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openimages numpy pandas scikit-learn opencv-python bing-image-downloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EB-QaUA44ES-",
        "outputId": "660f54d4-a28d-486e-cd3b-14d8742e127c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openimages in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: bing-image-downloader in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from openimages) (1.28.25)\n",
            "Requirement already satisfied: cvdata in /usr/local/lib/python3.10/dist-packages (from openimages) (0.0.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from openimages) (4.9.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openimages) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openimages) (4.66.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: botocore<1.32.0,>=1.31.25 in /usr/local/lib/python3.10/dist-packages (from boto3->openimages) (1.31.25)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->openimages) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from boto3->openimages) (0.6.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from cvdata->openimages) (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openimages) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openimages) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openimages) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openimages) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "1JGH_a93TAWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "# from openimages.download import download_images\n",
        "from bing_image_downloader import downloader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "vz-M_Rz3kA0p"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Functions"
      ],
      "metadata": {
        "id": "k7fg9cqyTESc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_folder(folder_path, num_images):\n",
        "    images = []\n",
        "    random_files = random.sample(os.listdir(folder_path), num_images)\n",
        "    for filename in random_files:\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "    return images\n",
        "\n",
        "def test_model(model, image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is not None:\n",
        "        img = cv2.resize(img, (64, 64))  # Resize the image to match the input size during training\n",
        "        img = img.reshape(1, -1) / 255.0  # Flatten and normalize the image\n",
        "        prediction = model.predict(img)\n",
        "        if prediction[0] == 1:\n",
        "            return \"calisthenics_spot\"\n",
        "        else:\n",
        "            return \"not_calisthenics_spot\"\n",
        "    else:\n",
        "        return \"Invalid image path or format\"\n",
        "\n",
        "\n",
        "def resize_images_by_percentage(image_folder, percentage, output_folder):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    resized_images = []\n",
        "\n",
        "    for filename in os.listdir(image_folder):\n",
        "        img_path = os.path.join(image_folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            new_width = int(img.shape[1] - (img.shape[1] * percentage))\n",
        "            new_height = int(img.shape[0] - (img.shape[0] * percentage))\n",
        "            resized_img = cv2.resize(img, (new_width, new_height))\n",
        "            resized_images.append(resized_img)\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            cv2.imwrite(output_path, resized_img)\n",
        "\n",
        "    return np.array(resized_images)"
      ],
      "metadata": {
        "id": "rexH8gECkYIo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resize calisthenics spots"
      ],
      "metadata": {
        "id": "vTf9cTtg3HeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the paths for calisthenics_spot and not_calisthenics_spot folders\n",
        "calisthenics_folder = \"/content/drive/Othercomputers/Meu computador/5-periodo/method/calisthenics_spot\"\n",
        "not_calisthenics_folder = \"/content/drive/Othercomputers/Meu computador/5-periodo/method/random_images_dataset\"\n",
        "\n",
        "# Load images from the calisthenics_spot folder\n",
        "num_calisthenics_images = 6552\n",
        "calisthenics_images = load_images_from_folder(calisthenics_folder, num_calisthenics_images)\n",
        "\n",
        "# Specify the percentage by which to resize the images\n",
        "resize_percentage = 0.8095238\n",
        "\n",
        "# Resize calisthenics_spot images by the specified percentage\n",
        "resized_calisthenics_folder = \"/content/drive/Othercomputers/Meu computador/5-periodo/method/resized_calisthenics_spotsss\"\n",
        "resized_calisthenics_images = resize_images_by_percentage(calisthenics_folder, resize_percentage, resized_calisthenics_folder)\n",
        "\n",
        "# # Download random images from the Open Images V6 dataset for the not_calisthenics_spot class\n",
        "num_not_calisthenics_images = 6552\n",
        "# class_label = \"not_calisthenics_spot\"\n",
        "# # download_images(limit=num_not_calisthenics_images, annotations=class_label,\n",
        "# #                 folder=not_calisthenics_folder)\n",
        "# downloader.download(query='', limit=num_not_calisthenics_images, output_dir=not_calisthenics_folder, adult_filter_off=False, force_replace=False, timeout=60, verbose=True)\n",
        "\n",
        "# Load images from the not_calisthenics_spot folder\n",
        "not_calisthenics_images = load_images_from_folder(not_calisthenics_folder, num_not_calisthenics_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpf-33cDkd0F",
        "outputId": "38687811-4675-4ada-da92-7b73d53ebbff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-eb366fed2886>:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(resized_images)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load images from folder\n"
      ],
      "metadata": {
        "id": "LJ1K1hsC3wV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the paths for calisthenics_spot and not_calisthenics_spot folders\n",
        "calisthenics_folder = \"/content/drive/Othercomputers/Meu computador/5-periodo/method/resized_calisthenics_spotsss\"\n",
        "not_calisthenics_folder = \"/content/drive/Othercomputers/Meu computador/5-periodo/method/random_images_dataset\"\n",
        "\n",
        "# Load images from the calisthenics_spot folder\n",
        "num_calisthenics_images = 6552\n",
        "calisthenics_images = load_images_from_folder(calisthenics_folder, num_calisthenics_images)\n",
        "\n",
        "# Load images from the not calisthenics_spot folder\n",
        "num_not_calisthenics_images = 6552\n",
        "not_calisthenics_images = load_images_from_folder(not_calisthenics_folder, num_not_calisthenics_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "eM-FFyGC2gGb",
        "outputId": "3cbcef79-cf61-40d5-c00d-a29d51919b59"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-fea17bfdccdb>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Load images from the not calisthenics_spot folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnum_not_calisthenics_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6552\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mnot_calisthenics_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_calisthenics_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_not_calisthenics_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-eb366fed2886>\u001b[0m in \u001b[0;36mload_images_from_folder\u001b[0;34m(folder_path, num_images)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_images_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mrandom_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrandom_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "f_-hRoHaTRmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create labels for the data\n",
        "calisthenics_labels = np.ones(shape=num_calisthenics_images, dtype=int)\n",
        "not_calisthenics_labels = np.zeros(shape=num_not_calisthenics_images, dtype=int)\n",
        "\n",
        "# Combine the data and labels for the model\n",
        "X = np.array(object=(calisthenics_images + not_calisthenics_images), dtype=object)\n",
        "y = np.concatenate((calisthenics_labels, not_calisthenics_labels))\n",
        "\n",
        "# Resize the images to a consistent size (e.g., 64x64)\n",
        "resized_images = [cv2.resize(image, (64, 64)) for image in X]\n",
        "\n",
        "# Normalize the pixel values of each image\n",
        "normalized_images = [image.astype('float32') / 255.0 for image in resized_images]\n",
        "\n",
        "# Convert the list of images to a NumPy array\n",
        "X_normalized = np.array(normalized_images)\n",
        "\n",
        "# Reshape the images to match the flattened size\n",
        "num_samples, height, width, channels = X_normalized.shape\n",
        "X_flattened = X_normalized.reshape(num_samples, -1)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_flattened, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the SVM classifier\n",
        "svm_classifier = SVC(kernel='linear', C=1.0)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZOGfHEok5if",
        "outputId": "0b094475-ae82-4e5c-ae82-496d07cbdd09"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6921022510492179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "iNEMKM0KTX1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "l1SD7sFFRSPQ",
        "outputId": "ee4d2bcf-3d83-4fb6-f68d-92aa2bcb671a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1e3ecc61ad6f>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Save the trained SVM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/Othercomputers/Meu computador/5-periodo/method/svm_model_1.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Load the trained SVM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'svm_classifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the model"
      ],
      "metadata": {
        "id": "BaFjdWsmT2FL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained SVM model\n",
        "model_filename = '/content/drive/Othercomputers/Meu computador/5-periodo/method/svm_model_1.pkl'\n",
        "joblib.dump(svm_classifier, model_filename)"
      ],
      "metadata": {
        "id": "r1C7Ynk9TxLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and test the model"
      ],
      "metadata": {
        "id": "c4SVCF-PT6IK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained SVM model\n",
        "loaded_model = joblib.load(model_filename)\n",
        "\n",
        "def test_model(model, image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(\"Failed to load the image.\")\n",
        "        return\n",
        "\n",
        "    # Preprocess the image: resize and normalize\n",
        "    resized_img = cv2.resize(img, (64, 64))\n",
        "    normalized_img = resized_img.astype('float32') / 255.0\n",
        "    flattened_img = normalized_img.reshape(1, -1)  # Reshape for prediction\n",
        "\n",
        "    # Make predictions using the loaded model\n",
        "    prediction = model.predict(flattened_img)\n",
        "\n",
        "    if prediction[0] == 1:\n",
        "        print(\"The image is a calisthenics_spot.\")\n",
        "    else:\n",
        "        print(\"The image is not a calisthenics_spot.\")\n",
        "\n",
        "# Path to the image you want to test\n",
        "test_image_path = \"/content/drive/Othercomputers/Meu computador/5-periodo/method/calisthenics_spot/teste/epa.png\"  # Replace with your test image path\n",
        "\n",
        "# Test the model using the loaded SVM model\n",
        "test_model(loaded_model, test_image_path)"
      ],
      "metadata": {
        "id": "w7LOmFriT9Gr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}